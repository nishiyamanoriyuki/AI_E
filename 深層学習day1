Section1) 入力層〜中間層
要点まとめ
入力層から中間層への流れは以下の通りである。入力された値と重みの積をとり、バイアスを足して活性化関数に通す。この値を次の層への入力として処理する。
機械学習ではこの重みおよびバイアスを適切化していくことが目的となる。
pythonでの実装はnumpyを使用してu1 = np.dot(x, W1) + b1と表す。

Section2) 活性化関数
要点まとめ
活性化関数とは次の層への出力の大きさを決める非線形の関数である。入力値によって、次の層への信号のON/OFFや強弱を定める働きをもつ。
中間層への活性化関数としては、relu,シグモイド、ステップ関数などが使われ、出力層への活性化関数としてはシグモイド、ソフトマックス、恒等関数などが使われる。
特にreluが使われることが多い。


Section3) 出力層
要点まとめ


Section4) 勾配降下法
要点まとめ

Section5) 誤差逆伝播法
要点まとめ


